

-- String and name handling
--------------------------------------------------------------------------------

A `Pos` is a byte offset into an implicit ByteString, a `Span` is a pair of
`Pos`s. In parsing, it's more efficient to only store these, since it's obvious
which ByteString we're operating on. During elaboration, spans are converted to
bona fide ByteStrings. ByteStrings are used for scope indexing and module
hierarchy indexing.

In a serialized module, we deep-copy all ByteStrings for internally bound names,
and also for all external (imported) names. I doubt that it makes a whole lot of
difference to hash-cons names. After all, names are only stored at points of
binding, and also once for each external name used in a module.

In deserialization, we can simply take ByteString slices of the ByteString being
deserialized, to read names. So we avoid allocating new strings for each name,
we just slice the binary file.

From bytestring-0.11.0.0, the representation is quite good: a ByteString only
has a single word top-level overhead compared to Span. So we don't bother
storing spans after elaboration.

- TODO: newtype wrap ByteString to implement better Hashable and Eq instances.
  The current instances call out to C code, but for short strings it's obviously
  better to use inlined Haskell.

What about names which are generated during elaboration, and do not come from
any source file? We don't want to generate lots of ByteStrings, and we want names
to be fast to generate (constant time, ideally). Since names are *not* compared
or computed with, except in displaying, the solution is to use an ADT definition
for generated names, such that leaves have ByteStrings, and nodes correspond to
combining or decorating names.

- QUESTION: what about using ByteString in parsing? I.e. can we build strings
  instead of spans? A string has a) a finalizer b) a start address c) a length.
  A parser keeps track of the current address and the end address. So we can get
  rather easily a string from a span, if we additionally keep around the
  finalizer in the Reader. This could be convenient. But it feels wasteful
  copying the finalizer all over the presyntax.

- QUESTION: what about ghc-style FastString:

   https://hackage.haskell.org/package/ghc-8.10.1/docs/FastString.html

  I say we're doing the wrong thing if we need O(1) string comparison! Scope
  checking in elaboration converts every name into an index, the name of an
  index is only ever relevant for printing. The memory consumption of all
  identifiers is also practically irrelevant, since almost every string slices a
  source file or an interface file, which are loaded anyway.

  What about PtrString? (in the same module) This could make sense as an unsafe
  version of Span, but it feels like a big safety & memory management hassle for
  negligible efficiency.

  In general, an elaborator doesn't massage or compare strings a lot! The point
  of scope checking is to process each string *once*, then forget about them
  altogether, until pretty printing.

-- Strictness at call and return sites
--------------------------------------------------------------------------------

Consider the following type:

    data S a = S !a

If we wrap all types of a function with S, we can observe in the generated Core
that this eliminates all potential forcing from the worker function. The reason is
that S disappears during worker-wrapping, turning into just an "a" in arguments and
(# a #) in the result. The arguments are annotated with "Unf=OtherCon []":

  https://downloads.haskell.org/~ghc/latest/docs/html/libraries/ghc-8.10.1/CoreSyn.html#v:OtherCon

Meaning that Core knows that they're already forced. In theory, S should completely eliminate
superfluous forcing from workers, by a) moving input forcing obligations to call sites b) returning
forced values.

In practice, does this work? I've done small-scale benchmark in github.com/AndrasKovacs/normalization-bench,
but there's no conclusive evidence. It might be the case that STG/cmm passes kill all superfluous forcing.

TODO: when setoidtt core works, benchmark S-wrapping in eval.
